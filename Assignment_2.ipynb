{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from pandas.api.types import CategoricalDtype\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "0  comp.sys.ibm.pc.hardware\n",
       "1     comp.sys.mac.hardware\n",
       "2                 rec.autos\n",
       "3           rec.motorcycles\n",
       "4                 sci.crypt\n",
       "5           sci.electronics\n",
       "6    soc.religion.christian\n",
       "7        talk.religion.misc"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data frames\n",
    "data_path = os.path.join(os.getcwd(), 'Data', 'PartA', '20ng_train.csv')\n",
    "trn_newsgroup = pd.read_csv(data_path, delimiter=',', compression='bz2')\n",
    "data_path2 = os.path.join(os.getcwd(), 'Data', 'PartA', '20ng_test.csv')\n",
    "tst_newsgroup = pd.read_csv(data_path2, delimiter=',', compression='bz2')\n",
    "data_path3 = os.path.join(os.getcwd(), 'Data', 'PartA', '20ng_labels.csv')\n",
    "lbl_newsgroup = pd.read_csv(data_path3, delimiter=',', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop class labels\n",
    "trn_newsgroup_targets = trn_newsgroup['class']\n",
    "trn_newsgroup = trn_newsgroup.drop(['class'], axis = 1)\n",
    "tst_newsgroup_targets = tst_newsgroup['class']\n",
    "tst_newsgroup = tst_newsgroup.drop(['class'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train rows: 5648\n",
      "Number of train columns: 1001\n",
      "Number of test rows: 1883\n",
      "Number of test columns: 1001\n",
      "0\n",
      "1489\n",
      "1193\n",
      "737\n",
      "1486\n",
      "0\n",
      "0\n",
      "743\n",
      "5648\n"
     ]
    }
   ],
   "source": [
    "print('Number of train rows: {}'.format(trn_newsgroup.shape[0]))\n",
    "print('Number of train columns: {}'.format(trn_newsgroup.shape[1]))\n",
    "print('Number of test rows: {}'.format(tst_newsgroup.shape[0]))\n",
    "print('Number of test columns: {}'.format(tst_newsgroup.shape[1]))\n",
    "trn_newsgroup.describe()\n",
    "tst_newsgroup.describe()\n",
    "\n",
    "zeros = 0\n",
    "ones = 0 \n",
    "twos = 0\n",
    "threes = 0\n",
    "fours = 0\n",
    "fives = 0\n",
    "sixes = 0\n",
    "sevens = 0\n",
    "for row in trn_newsgroup_targets:\n",
    "    if(trn_newsgroup_targets[row] == 0): \n",
    "        zeros = zeros + 1 \n",
    "    if(trn_newsgroup_targets[row] == 1): \n",
    "        ones = ones + 1\n",
    "    if(trn_newsgroup_targets[row] == 2): \n",
    "        twos = twos + 1\n",
    "    if(trn_newsgroup_targets[row] == 3): \n",
    "        threes = threes + 1\n",
    "    if(trn_newsgroup_targets[row] == 4): \n",
    "        fours = fours + 1\n",
    "    if(trn_newsgroup_targets[row] == 5): \n",
    "        fives = fives + 1\n",
    "    if(trn_newsgroup_targets[row] == 6): \n",
    "        sixes = sixes + 1\n",
    "    if(trn_newsgroup_targets[row] == 7): \n",
    "        sevens = sevens + 1\n",
    "print(zeros)\n",
    "print(ones)\n",
    "print(twos)\n",
    "print(threes)\n",
    "print(fours)\n",
    "print(fives)\n",
    "print(sixes)\n",
    "print(sevens)\n",
    "print(zeros+ones+twos+threes+fours+fives+sixes+sevens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==== Question 1.1 ====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the training set, we see that there are 5648 entries of which 1000 words and their frequencies are being checked. Obviously when dealing with large texts the word frequencies will often be 0 or extremely low. This is the case in our data set as the mean is 0.002292. There are 8 possible classes that the classifier can label an entry as. And from looking at the distribution of these "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==== Question 1.2 ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing has 1883 entries of newsgroup documents. Resulting in a 75 to 25 percent split in training to testing data. This decision to have significantly more training entries brings its drawbacks and benefits. The larger you make a training set the more information the classifier will have to improve its accuracy during testing and in practice. However, the more testing data you have, the more we understand how accurate the classifier will be in practice. Essentially in prioritising training, we are gaining a more accurate predictor while losing our ability to know how  accurate the classifier will be on previously unseen entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==== Question 1.3 ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
